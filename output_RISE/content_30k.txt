1 Introduction

The CHERI[^1] architecture extension improves computer security by checking all memory accesses in hardware. Under CHERI, memory cannot be accessed with integer addresses, but must pass through a capability[WMSN19] - unforgeable tokens that grant fine-grained access to ranges of memory. Instead of generating them from scratch, capabilities must be derived from another capability with greater permissions. This vastly reduces the scope of security violations through spatial errors (e.g. buffer overflows[SPWS13]), and creates interesting opportunities for software compartmentalization[WWNM15].

Industry leaders have recognized the value CHERI provides. Arm Inc have manufactured the Morello System-on-Chip which incorporates CHERI into the Armv8.2 ISA. However some features haven’t fully embraced CHERI, such as Arm’s Scalable Vector Extension (SVE) , which is designed to remain in use well into the future[SBBE17]. Supporting this and other scalable vector ISAs is essential to CHERI’s long-term relevance.

1.1 Motivation

Modern vector implementations all provide vector load/store instructions. Vector-enabled CHERI CPUs must support those instructions, but adding CHERI’s bounds-checking for each vector element could impact performance.

Vector memory access performance is critical, because vectors aren’t just used for computation. For example, glibc uses vector memory accesses to implement memcpy where available. These implementations are written in assembly and heavily optimized. If they hit the cache, extra cycles of bounds-checking for each access could make a difference.

memcpy also raises the important question of how vectors interact with capabilities. In non-CHERI processors, memcpy will copy pointers around in memory. An equivalent CHERI-enabled vector memcpy would need to load/store capabilities from vectors without violating security guarantees.

The goal of this project is to investigate the impact of, and the roadblocks for, integrating a scalable vector architecture with CHERI’s memory protection system. Specifically we focus on integrating the RISC-V Vector extension[Xyz21] (RVV) with the CHERI-RISC-V ISA, with the aim of enabling a future CHERI-RVV implementation and informing the approach for a future CHERI Arm SVE implementation.

The full dissertation addresses nine hypotheses, but for the sake of brevity we examine four here: 1. It is possible to use CHERI capabilities as memory references in all vector instructions. 2. The capability bounds checks for vector elements within a known range (e.g. a cache line) can be performed in a single check, amortizing the cost. 3. Legacy vector code can be compiled into a pure-capability form with no changes. 4. It is possible for a vector architecture to load, store, and manipulate capabilities in vector registers without violating CHERI security principles.

2 Background

TODO - something here?

2.1 The RVV vector model

RVV defines thirty-two vector registers, each of an implementation-defined constant width VLEN. These registers can be interpreted as vectors of elements. The program can configure the size of elements, and the implementation defines a maximum width ELEN.

RVV instructions operate on groups of vector registers. The implementation stores two variables, vstart and vl, which define the start and length of the “body” section within the vector. Instructions only operate on body elements, and some allow elements within the body to be masked out and ignored.

2.1.1 Exception handling

If synchronous exceptions (e.g. invalid memory access) or asynchronous interrupts are encountered while executing a vector instruction, RVV defines two ways to trap them. In both cases, the PC of the instruction is saved in a register “*epc”.

If the instruction should be resumed after handling the trap, e.g. in the case of demand paging, the implementation may use a “precise trap”. The implementation must complete all instructions up to “*epc”, and no instructions after that, and save the index of the offending vector element in “vstart”. Within the instruction, all vector elements before “vstart” must have committed their results, and all other elements must either 1) not have committed results, or 2) be idempotent e.g. repeatable without changing the outcome.

In other cases “imprecise traps” may be used, which allow instructions after “*epc” and vector elements after “vstart” to commit their results. “vstart” must still be recorded, however.

2.2 CHERI

In CHERI, addresses/pointers are replaced with capabilities: unforgeable tokens that provide specific kinds of access to an address within a range of memory. The above statement is enough to understand what capabilities contain[^13]:

-   Permission bits, to restrict access

-   The cursor, i.e. the address it currently points to

-   The bounds, i.e. the range of addresses this capability could point to

A great deal of work has gone into compressing capabilities down into a reasonable size (see [WJXF19]), and using the magic of floating-point all of this data has been reduced to just 2x the architectural register size. For example, on 64-bit RISC-V a standard capability is 128-bits long. The rest of this dissertation assumes capabilities are 128-bits long for simplicity.

A CHERI implementation has to enforce three security properties about its capabilities[WNWR20 Section 1.2.1]:

-   Provenance - Capabilities must always be derived from valid manipulations of other capabilities.

-   Integrity - Corrupted capabilities cannot be dereferenced.

-   Monotonicity - Capabilities cannot increase their rights.

Integrity is enforced by tagging registers and memory. Every 128-bit register and aligned 128-bit region of memory has an associated tag bit, which denotes if its data encodes a valid capability[^14]. If any non-capability data is written to any part of the region the tag bit is zeroed out. Instructions that perform memory accesses can only do so if the provided capability has a valid tag bit. As above, significant work has gone into the implementation to reduce the DRAM overhead of this method (see [JWKM17]).

Provenance and Monotonicity are enforced by all instructions that manipulate capabilities. If an implementation detects a violation of either property, it will zero out the tag bit and rely on Integrity enforcement to ensure it is not dereferenced. Some CHERI-enabled architectures, such as CHERI-RISC-V, also raise a synchronous exception when this occurs.

2.2.1 CHERI-RISC-V ISA

[WNWR20] describes the latest version of the CHERI architecture (CHERI ISAv8) and proposes applications to MIPS, x86-64, and RISC-V. CHERI-RISC-V is a mostly straightforward set of additions to basic RISC-V ISAs. It adds thirty-two general-purpose capability registers, thirty-two Special Capability Registers (SCRs), and many new instructions.

The new general-purpose capability registers are each of size CLEN = 2 * XLEN plus a tag bit. While there is always a logical distinction between the integer registers x0-x31 and capability registers cx0-cx31, the architecture may store them in a Split or Merged register file. A Split register file stores the integer registers separately from capability registers, so programs can manipulate them independently. A Merged register file stores thirty-two registers of length CLEN, using the full width for the capability registers and aliasing the integer registers to the bottom XLEN bits. Under a merged register file, writing to an integer register makes the capability counterpart invalid.

Many of the new SCRs are intended to support the privileged ISA extensions for e.g. hypervisors or operating systems. The emulator doesn’t use these, so their SCRs are not listed here, but there are two highly relevant SCRs for all modes: the Program Counter Capability and the Default Data Capability.

The PCC replaces the program counter and adds more metadata, ensuring instruction fetches have the same security properties as normal loads and stores. The DDC is used to sandbox integer addressing modes. CHERI-RISC-V includes new instructions which use integer addressing, and allows legacy (i.e. integer addressed) code to function on CHERI systems without recompiling for CHERI-RISC-V. These instructions all use integer addresses relative to the DDC, and the DDC controls the permissions those instructions have.

2.2.2 Capability and Integer encoding mode

CHERI-RISC-V specifies two encoding modes, selected using a flag in the PCC flags field. Capability mode modifies the behaviour of pre-existing instructions (e.g. Load Byte) to take address operands as capabilities.

Integer mode seeks to emulate a standard CHERI-less RISC-V architecture as much as possible. All pre-existing RISC-V memory access instructions take address operands as integers, which are dereferenced relative to the DDC[^15]. New CHERI instructions may still be used to dereference and inspect capability registers, but all other instructions access registers in an integer context i.e. ignoring the upper bits and tag from merged register files.

3 Hardware emulation investigation

In order to experiment with integrating CHERI and RVV, we implemented a RISC-V emulator in the Rust programming language named riscv-v-lite. The emulator supports the Multiply, CSR, Vector, and CHERI extensions, and was also used as the base for capabilities-in-vectors research.

3.1 Developing the emulator

The emulator is very modular, such that each ISA extension is defined as a separate module which can easily be plugged into different processor implementations. Each ISA module uses a “connector” structure, containing e.g. virtual references to register files and memory, which allows different processors to reuse ISA modules despite using different register file/memory implementations.

Each processor implements a single stage pipeline. Instructions are fetched, decoded with a common decoder function[^19], and executed. The processor asks each ISA module in turn if it wants to handle the instruction, and uses the first module to say yes. If the ISA module returns a new PC value it is immediately applied, otherwise it is automatically incremented. This structure easily represents basic RISC-V architectures, and can scale up to support many different new modules.

3.1.1 Emulating CHERI

Manipulating CHERI capabilities securely and correctly is a must for any CHERI-enabled emulator. Capability encoding logic is not trivial by any means, so the cheri-compressed-cap C library was re-used rather than implementing it from scratch. There were a few issues with implementing Rust/C interoperation, which are addressed in the dissertation.

The CHERI-RISC-V documentation contains formal specifications of all new CHERI instructions. These definitions are used in the CHERI-RISC-V formal model[^24], and require a few helper functions (see [WNWR20 Chapter 8.2]). The rust-cheri-compressed-cap library also defines those helper functions, so the formal definitions can be ported directly into the emulator.

The above work is available online[^25], and includes documentation for all C functions[^26] (which were not previously documented). –>

3.1.1.1 Integrating into the emulator

Integrating capabilities into the emulator was relatively simple thanks to the modular emulator structure.

CHERI-specific memory and register file types were created, which could expose both integer and capability functionality. The CHERI register file exposed integer-mode and capability-mode accesses, and memory was built in three layers: 1) Normal integer-addressed memory 2) Capability-addressed CHERI memory, which checks capability properties before accessing 1) 3) Integer-mode CHERI memory, which adds an integer address to the DDC before accessing 2)

This approach meant code for basic RV64I operations did not need to be modified for CHERI at all - simply passing the integer-mode memory and register file would perform all relevant checks.

Integrating capability instructions was also simple. Two new ISA modules were created: XCheri64 for the new CHERI instructions, and Rv64imCapabilityMode to override legacy instructions in capability-encoding-mode. Integer addresses were changed to capabilities throughout, memory and register file types were changed as described above, and the PCC/DDC were added.

To reduce the chances of accidentally converting integers to capabilities, the emulator defines a SafeTaggedCap type: a sum type which represents either a CcxCap with the tag bit set, or raw data with the tag bit unset. This adds type safety, as the Rust compiler forces every usage of SafeTaggedCap to consider both options, preventing raw data from being interpreted as a capability by accident and enforcing Provenance.

3.1.2 Emulating vectors

Vector instructions are executed by a Vector ISA module, which stores all registers and other state. VLEN is hardcoded as 128-bits, chosen because it’s the largest integer primitive provided by Rust that’s large enough to hold a capability. ELEN is also 128-bits, which isn’t supported by the specification, but is required for capabilities-in-vectors. Scaling VLEN and ELEN higher would require new numeric types that were more than 128-bits long.

To support both CHERI and non-CHERI execution pointers are separated into an address and a provenance[^28]. The vector unit retrieves an address + provenance pair from the base register, generates a stream of addresses to access, then rejoins each address with the provenance to access memory. When using capabilities, provenance is defined in terms of the base register e.g. “the provenance is provided by capability register X”, or defined by the DDC in integer mode[^29]. On non-CHERI platforms the vector unit doesn’t check provenance.

3.1.2.1 Fast-path checking phase

TODO the emulator describes full-access checking, but we removed that part. TODO greatly cut this down

The initial motivation for this project was investigating the impact of capability checks on performance. Rather than check each element’s access individually, we determine a set of “fast-path” checks which check multiple elements at once. The emulator computes the “tight bounds” for each access, i.e. the exact range of bytes that will be accessed, and doing a single capability check with that bounds. The full thesis describes calculating “tight bounds” for each access type, and ways that architectural complexity can be traded off to calculate wider bounds.

If the tight bounds don’t pass the capability check, the emulator raises an imprecise trap and stops immediately. In the case of fault-only-first loads, where synchronous exceptions (e.g. capability checks) are explicitly handled, the access continues regardless and elements are checked individually. This is also the expected behaviour if a capability check for wider bounds fails. The emulator deviates from the spec in that vstart is not set when the tight bounds check fails, as it does not know exactly which element would have triggered the exception. A fully compliant machine must check each access to find vstart in these cases.

3.1.2.2 Integer vs. Capability encoding mode

CHERI-RISC-V defines two execution modes that the program can switch between. In Integer mode “address operands to existing RISC-V load and store opcodes contain integer addresses” which are implicitly dereferenced relative to the default data capability, and in Capability mode those opcodes are modified to use capability operands.

Integer mode was included in the interests of maintaining compatibility with legacy code that hasn’t been adapted to capabilities. As similar vector code may also exist, CHERI-RVV treats vector memory access instructions as “existing RISC-V load and store opcodes” and requires that they respect integer/capability mode.

We do not define new mode-agnostic instructions, which means vector programs cannot mix capability and integer addressing without changing encoding modes. This may make incremental adoption more difficult, and in the future we may examine existing vanilla RVV programs to determine if it’s worth adding those instructions.

3.2 Fast-path calculations

A fast-path check can be performed over various sets of elements. The emulator chooses to perform a single fast-path check for each vector access, calculating the tight bounds before starting the actual access, but in hardware this may introduce prohibitive latency. Here, we explore other possible approaches for hardware.

3.2.1 Possible fast-path outcomes

In some cases, a failed address range check may not mean the access fails. The obvious case is fault-only-first loads, where capability exceptions may be handled without triggering a trap. Implementations may also choose to calculate wider bounds than accessed for the sake of simplicity, or even forego a fast-path check altogether. Thus, a fast-path check can have four outcomes depending on the circumstances.

A Success means no per-access capability checks are required. Likely-Failure and Unchecked results mean each access must be checked, to see if any of them actually raise an exception. Unfortunately, accesses still need to be checked under Failure, because both precise and imprecise traps need to report the offending element in vstart[^30].

Because all archetypes may have Failure or Likely-Failure outcomes, hardware must provide a fallback slow-path for each archetype which checks/performs each access in turn. In theory, a CHERI-RVV specification could relax the vstart requirement for imprecise traps, and state that all capability exceptions trigger imprecise traps. In this case, only archetypes that produce Likely-Failure outcomes need the slow-path. However, it is likely that for complexity reasons all masked accesses will use wide ranges, thus producing Likely-Failure outcomes and requiring slow-paths for all archetypes anyway. Because the Likely-Failure and Failure cases require the slow-path anyway, computing the fast-path can only be worthwhile if Success is the common case.

  Type             Meaning
  ---------------- ---------------------------
  Success          All accesses will succeed
  Failure          At least one access will
                   raise an exception
  Likely-Failure   At least one access may
  or Unchecked     raise an exception

3.2.2 m-element known-range fast-paths

A hardware implementation of a vector unit may be able to issue m requests within a set range in parallel. For example, elements in the same cache line may be accessible all at once. In these cases, checking elements individually would either require m parallel bounds checks, m checks’ worth of latency, or something in-between. In this subsection we consider a fast-path check for m elements.

Capability checks can be split into two steps: address-agnostic (e.g. permissions checks, bounds decoding) and address-dependent (e.g. bounds checks). Address-agnostic steps can be performed before any bounds checking, and should add minimal start-up latency (bounds decoding must complete before the checks anyway, and permission checks can be performed in parallel). Once the bounds are decoded the actual checks consist of minimal logic[^31], so a fast-path must have very minimal logic to compete.

We first consider unit and strided accesses, and note two approaches. First, one could amortize the checking logic cost over multiple sets of m elements by operating in terms of cache lines. Iterating through all accessed cache lines, and then iterating over the elements inside, allows the fast-path to hardcode the bounds width and do one check for multiple cycles of work (if cache lines contain more than m elements). Cache-line-aligned allocations benefit here, as all fast-path checks will be in-bounds i.e. Successful, but misaligned data is guaranteed to create at least one Likely-Failure outcome per access (requiring a slow-path check). Calculating tight bounds for the m accessed elements per cycle could address this.

For unit and strided accesses, the bounds occupied by m elements is straightforward to calculate, as the addresses can be generated in order. The minimum and maximum can then be picked easily to generate tight bounds. An m-way multiplexer is still required for taking the minimum and maximum, because evl and vstart may not be m-aligned. If m is small, this also neatly extends to handle masked/inactive elements. This may use less logic overall than m parallel bounds checks, depending on the hardware platform[^32], but it definitely uses more logic than the cache-line approach. Clearly, there’s a trade-off to be made.

Indexed fast-paths are more complicated, because the addresses are unsorted. The two approaches above have different advantages for indexed accesses. If the offsets/indices are spatially close, just not sorted, cache line checks may efficiently cover all elements. An implementation could potentially cache the results, and refer back for each access, instead of trying to iterate through cache lines in order. Otherwise a m-way parallel reduction could be performed to find the min and max, but that would likely take up more logic than m comparisons. This may be a moot point depending on the cache implementation though - if the m accesses per cycle must be in the same cache line, and the addresses are spread out, you’re limited to one access and therefore one check per cycle regardless.

In summary, there are fast-path checks that consume less logic than m parallel checks in certain circumstances. Even though a slow-path is always necessary, it can be implemented in a slow way (e.g. doing one check per cycle) to save on logic. Particularly if other parts of the system rely on constraining the addresses accessed in each cycle, a fast-path check can take advantage of those constraints.

3.3 Testing and evaluation

We tested the emulator using a set of test programs described in later sections, and found that all instructions were implemented correctly.

[hyp:hw_cap_as_vec_mem_ref] - Feasibility

This is true. All vector memory access instructions index the scalar general-purpose register file to read the base address, and CHERI-RVV implementations can simply use this index for the scalar capability register file instead. This can be considered through the lens of adding CHERI to any RISC-V processor, and in particular adding Capability mode to adjust the behaviour of legacy instructions. RVV instructions can have their behaviour adjusted in exactly the same way as the scalar memory access instructions.

That approach then scales to other base architectures that have CHERI variants. For example, Morello’s scalar Arm instructions were modified to use CHERI capabilities as memory references[21 Section 1.3], so one may simply try to apply those modifications to e.g. Arm SVE instructions. This only works where Arm SVE accesses memory references in the same way as scalar Arm instructions did i.e. through a scalar register file.

Arm SVE has some addressing modes like u64base, which uses a vector as a set of 64-bit integer addresses[19]. This has more complications, because simply dereferencing integer addresses without a capability is insecure. Would a CHERI version convert this mode to use capabilities-in-vectors, breaking compatibility with legacy code that expects integer references? Another option would be to only enable this instruction in Integer mode, and dereference relative to the DDC. It’s possible to port this to CHERI, but requires further investigation and thought.

[hyp:hw_cap_bounds_checks_amortized] - Fast-path checks

This is also true, at least for Successful accesses. Because the RVV spec requires that the faulting element is always recorded[Xyz21 Section 17], a Failure due to a capability violation requires elements to be checked individually. CHERI-RVV could change the specification so the faulting element doesn’t need to be calculated, which would make Failures faster, but that still requires Likely-Failures to take the slow-path.

There are many ways to combine the checks for a set of vector elements, which can take advantage of the range constraints. For example, a unit-stride access could a hierarchy of checks: cache-line checks until a Likely-Failure, then tight m-element bounds until a Likely-Failure, then the slow-path. However, the choice of fast-path checks is inherently a trade-off between latency, area, energy usage, and more. Picking the right one for the job is highly dependent on the existing implementation, and indeed an implementation may decide that parallel per-element checks is better than a fast-path.

4 The CHERI-RVV software stack

This chapter, being less relevant to RISE/hardware security, has been greatly condensed.

As part of the project, we considered how adding CHERI to RVV would affect the software stack. We tested our hypotheses by adding CHERI-RVV to Clang, which is the current focus for CHERI and RVV compiler development. Clang supports three methods of vectorization:

1.  Auto-vectorization, where the compiler converts scalar code to vector code
2.  Vector intrinsics, where the programmer writes vector code and the compiler handles low-level details e.g. register allocation
3.  Inline assembly, where the programmer directly describes the assembly instructions to execute.

Clang currently supports intrinsics and inline assembly for RVV, but not auto-vectorization yet. This just requires engineering work - Arm SVE, a similar model, has great auto-vectorization.

4.1 Our changes to CHERI-Clang

The first step was to fix up the pre-existing RVV definition in Clang to use capability registers for the base address. This meant CHERI-RVV assembly code could be compiled, as long as it explicitly referenced capability registers. Unfortunately, non-CHERI inline assembly could not be automatically compiled under this method.

We investigated updating vector intrinsics to support CHERI, but found the code defining the intrinsics was more complicated than for assembly. We believe it is possible to update the intrinsics, but it requires significant engineering work. Other experiments, such as creating C functions to replace the intrinsics, ran into more significant problems. One of these problems involved storing vectors to the stack.

4.1.1 Storing scalable vectors on the stack

If a program uses too much data, or calls a function which may overwrite register values, the compiler will save/restore those register values to memory on the stack. This also applies to multiprocessing systems where a process can be paused, have the state saved, and resume later. RVV provides whole-register memory access instructions explicitly to make this process easy[Xyz21 Section 7.9].

CHERI-Clang contains an LLVM IR pass[^42] which enforces strict bounds on so-called “stack capabilities” (capabilities pointing to stack-allocated data), which requires knowing the size of the data. This pass requires the size to be known at compile-time, but scalable vectors do not have known sizes until runtime and so cannot currently be stored on the stack. This can be fixed with engineering effort - on non-CHERI platforms Clang simply finds VLEN at runtime.

4.2 Testing and evaluation

TODO summarize testing and evaluation

5 Capabilities-in-vectors

Implementing memcpy correctly for CHERI systems requires copying the tag bits as well as the data. As it stands, any vectorized memcpy on the systems described in previous chapters will not copy the tag bits, because the vector registers cannot store the tag bits and indeed cannot store valid capabilities. memcpy is very frequently vectorized, so it’s vital that CHERI-RVV can implement it correctly. Manipulating capabilities-in-vectors could also accelerate CHERI-specific processes, such as revoking capabilities for freed memory[XWAF19].

5.1 Extending the emulator

We defined three goals for capabilities-in-vectors:

1.  Vector registers should be able to hold capabilities.
2.  At least one vector memory operation should be able to load/store capabilities from vectors.
    -   Because memcpy should copy both integer and capability data, vector memory operations should be able to handle both together.
3.  Vector instructions should be able to manipulate capabilities.
    -   Clearing tag bits counts as manipulation.

First, we considered the impact on the theoretical vector model. We decided that any operation with elements smaller than CLEN cannot output valid capabilities under any circumstances[^44], meaning a new element width equal to CLEN must be introduced. We set ELEN = VLEN = CLEN = 128[^45] for our vector unit.

Two new memory access instructions were created to take advantage of this new element width, and the vector model was adjusted to support 128-bit elements. Similar to the CHERI-RISC-V LC/SC instructions we implemented 128-bit unit-stride vector loads and stores, which took over officially-reserved encodings[^46] we expected official versions to use. We have not tested other types of access, but expect them to be noncontroversial. Indexed accesses require specific scrutiny, as they may be expected to use 128-bit offsets on 64-bit systems.

The next step was to add capability support to the vector register file. Our approach to capabilities-in-vectors is similar in concept to CHERI-RISC-V’s Merged scalar register file, in that the same bits of a register can be accessed in two contexts: an integer context, zeroing the tag, or a capability context which maintains the current tag. The only instructions which can access data in a capability context are 128-bit memory accesses[^47]. All other instructions read out untagged integer data and clear tags when writing data.

A new CHERI-specific vector register file was created, where each register is a SafeTaggedCap i.e. either zero-tagged integer data or a valid tagged capability. This makes it much harder to accidentally violate Provenance, and reuses the code path (and related security properties) for accessing capabilitie