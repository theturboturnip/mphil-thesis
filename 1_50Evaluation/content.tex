\documentclass[../thesis]{subfiles}
\begin{document}

\chapter{Evaluation\label{chap:eval}}
This project has two main research outcomes: an implementation for a potential CHERI-RVV specification, and a set of hypotheses/conclusions that can inform future work on combining scalable vector models with CHERI.
This chapter describes the testing process for the emulator and concludes by summarizing the conclusions from previous chapters.

\section{Testing the emulator}
In order to verify the correct behaviour of the emulator, a set of self-checking integration test C programs were constructed.
All the programs follow the same pattern: each test program contains multiple tests, which each initialize an environment, perform the action under test, and check the impact on the environment was correct.
The individual test results are combined into a 64-bit bit vector and written to a special I/O memory location.
A bit vector noting which tests were run is also written to I/O memory, because some compilers or architectures do not support all tests.

Four compilers are tested, described in detail in \cref{chap:software}.
They include a build of GCC with support for vector intrinsics (\cref{appx:building_rvv_gcc_toolchain}), a binary distribution of Clang/LLVM-13, a custom build of Clang/LLVM-15, and a custom build of CHERI-Clang (based on LLVM 13) with changes to support RVV.
32-bit and 64-bit non-CHERI architectures are tested, along with 64-bit CHERI in Capability and Integer modes (\cref{chap:bg:subsec:cheriencodingmode}).
This section describes the tests in more detail, and notes any limitations in the software stack that prevent testing under some compilers/architectures.

% \todomark{Note somewhere that GCC support isn't a priority as of Dec 2021 https://github.com/riscv-collab/riscv-gcc/issues/320}

\subsection{\code{hello\_world}}
\code{hello\_world} runs three small functions which calculate Fibonacci numbers and factorials, testing that the emulator can handle basic programming constructs like recursive functions.
Fibonacci is calculated in two ways: once with a simple recursive function, and once with \emph{memoization} where previous outputs are cached in a static array.
The tests compile on all compilers, and output the correct results on all architectures.
\begin{table}[h]
    \centering
    \CatchFileDef{\tablehelloworld}{1_50Evaluation/data/hello_world_rows.tex}{}
    \begin{tabular}{rcccccc}
    \tablehelloworld
    \end{tabular}
    \caption{\code{hello\_world} results --- Basic program tests}\label{tab:fullresults:helloworld}
\end{table}


\subsection{\code{vector\_memcpy}}
\code{vector\_memcpy} is generated from a Python script, and consists of fifty-seven tests of different vector memory access archetypes under various configurations (\cref{tab:vectormemcpyschemes}).
Each of the nine test schemes are replicated for multiple \code{vtype} values, such that each individual LMUL and SEW value is tested.
These tests are run under \emph{harnesses}, which provide setup and self-checking code for common cases:
The Vanilla harness tests a simple \code{memcpy} between two arrays;
Masked tests that every other element is copied, not all of them;
Segmented tests a \code{memcpy} into four separate output arrays, each a different field of a four-field structure.
There is also a special test for fault-only-first: FoF loads are performed at the edge of mapped memory, and the test verifies that out-of-bounds exceptions are swallowed and \code{vl} is reduced accordingly.

All tests were successful when they ran, showing the emulator is correctly emulating the instructions, but in some cases testbenches weren't available.
The full set of test results is available in \cref{chap:fullresults:vectormemcpy}.

\begin{table}[h]
    \centering
    \begin{tabular}{lcc}
    \toprule
        Test Scheme & Harness & Compilers \\
        \midrule
        Unit Stride & Vanilla & All \\
        Strided & Vanilla & All \\
        Indexed & Vanilla & All \\
        Whole Register & Vanilla & All \\
        Fault-only-First & Vanilla & All \\
        
        Unit Stride (Masked) & Masked & All \\
        Bytemask Load & Masked & \code{llvm-15} only \\
        
        Unit Stride (Segmented) & Segmented & All \\

        Fault-only-First Boundary & - & All \\
         \bottomrule
    \end{tabular}
    \caption{\code{vector\_memcpy} test schemes and harnesses}
    \label{tab:vectormemcpyschemes}
\end{table}


\subsubsection{Compiler differences}\label{chap:eval:subsec:compilerdifferences}
While most compilers support all memory access archetypes, there are a few notable exceptions.
GCC has the most: there is no support for fractional LMUL or bytemask accesses, the intrinsics for segmented accesses are named differently, and fault-only-first intrinsics emit incorrect instructions\footnote{On GCC, fault-only-first intrinsics seem to emit \code{vsetvli}.}.
GCC RVV support has been deprioritized in favor of LLVM\footnote{\url{https://github.com/riscv-collab/riscv-gcc/issues/320}}, so the rough edges make sense.
LLVM-13-based compilers (including CHERI-Clang) support all specified archetypes except bytemask accesses.
CHERI-Clang doesn't support intrinsics, but all inline assembly support is intact.
Support for bytemask accesses is only available in LLVM-14 and up.

\subsection{\code{vector\_memcpy\_pointers}}
\code{vector\_memcpy\_pointers} tests the behaviour of \code{memcpy} with capabilities-in-vectors, by copying an array of data structures that hold pointers to static data.
On CHERI platforms, even in Integer mode, capability pointers are used and copied.
The first test simply copies the data and tests that all the copied pointers still work, which succeeds on all compilers/architectures.
The second test is CHERI-exclusive, and invalidates all pointers during the copy process by performing integer arithmetic on the vector registers.
The copied pointers are examined to make sure their tag bits are all zeroed, and this test succeeds on both CHERI configurations.

\begin{table}[h]
    \centering
    \CatchFileDef{\tablevecmemcpypointers}{1_50Evaluation/data/vector_memcpy_pointers_rows}{}
    \begin{tabular}{rcccccc}
    \tablevecmemcpypointers
    \end{tabular}
    \caption{\code{vector\_memcpy\_pointers} results}\label{tab:fullresults:vectormemcpyptrs}
\end{table}

\subsection{Summary}
All tests passed where available, and all tests were available on at least one compiler.
This shows the emulator is correctly executing vector instructions, and that it is possible to correctly \code{memcpy} capabilties in vector registers.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagebreak
% \section{Summarizing hypotheses}
\section{Conclusion}
In this dissertation I have presented a possible fusion of CHERI and RVV implemented in an emulator (\cref{chap:hardware}), explored the impact on the software stack (\cref{chap:software}), and extended the RVV instruction set/vector model to store capabilities in vectors (\cref{chap:capinvec}).
Throughout these chapters I have also presented conclusions to a set of hypotheses (\cref{tab:hypotheses}), which prove the general viability of adding scalable vector models to CHERI processsors.

\cref{hyp:hw_cap_as_vec_mem_ref} proved the most essential point, that a blanket replacement of all memory references with capabilities in all RVV instructions is valid.
\cref{hyp:hw_cap_bounds_checks_amortized} then alleviated performance concerns by showing it was possible to combine the required capability checks for all vector accesses, amortizing the overall cost of checking, although with varying practical benefit.

On the software side \cref{hyp:sw_vec_legacy,hyp:sw_pure_compat} showed that (in theory) non-CHERI vectorized code could be run on CHERI systems, and could also be recompiled for pure-capability execution with no source code changes, but that CHERI-Clang's current state adds some practical limitations.
\cref{hyp:sw_stack_vectors,hyp:sw_multiproc} address the pausing and resuming of vector code, particularly saving and restoring variable-length architectural state, concluding that it is entirely possible but will require software adjustments.

Through a limited investigation of capabilities-in-vectors, \cref{hyp:cap_in_vec_storage,hyp:cap_in_vec_load_store,hyp:cap_in_vec_manip} showed that a highly constrained implementation could enable a fully-functional vectorized \code{memcpy} without violating CHERI security principles.
It should be possible to extend the CHERI-RVV ISA with vector equivalents of existing CHERI scalar instructions, but I did not investigate this further.

Overall, it is clear that scalable vector models can be adapted to CHERI without significant loss of functionality.
While most of the hypotheses are general enough to cover other scalable models, e.g. Arm SVE, any differences from RVV's model will require careful examination.
Given the importance of vector processing to modern computing, and thus its importance to CHERI, I hope that this research and the software artifacts of this project (see \cref{appx:artifacts}) pave the way for future vector-enabled CHERI processor implementations.

% The hypotheses, reproduced in \cref{tab:hypothesis_outcome}, are evaluated in \todoref{hardware hyp, software hyp, cap-in-vec hyp}.
% They come to the broad conclusion that adapting RVV to a CHERI architecture is possible, and that other vector models like Arm SVE can be adapted in part\footnote{Further examination is required for some addressing modes.}, but the current software stack does not make writing CHERI-RVV programs easy.
% In particular RVV intrinsics can and should be ported to CHERI-Clang, and auto-vectorization for RVV and CHERI-RVV would simplify the situation further.
% The limited investigation of capabilities-in-vectors shows that minimal implementations designed to enable \code{memcpy} can avoid violating CHERI security principles, but adding more advanced capability manipulations requires careful consideration.

% \begin{table}[h]
%     \centering
%     \begin{tabular}{lp{0.6\textwidth}cl}
%     \toprule
%         \multicolumn{2}{l}{Hypothesis} & In Theory & In Practice \\
%         \midrule
%         \ref*{hyp:hw_cap_as_vec_mem_ref} & \gethyptext{hyp:hw_cap_as_vec_mem_ref} & True  & True \\
%         \ref*{hyp:hw_cap_bounds_checks_amortized} & \gethyptext{hyp:hw_cap_bounds_checks_amortized} & True & Benefit Varies \\
%         \ref*{hyp:sw_vec_legacy} & \gethyptext{hyp:sw_vec_legacy} & True & True (ASM) \\
%         \ref*{hyp:sw_pure_compat} & \gethyptext{hyp:sw_pure_compat} & True & False \\
%         \ref*{hyp:sw_stack_vectors} & \gethyptext{hyp:sw_stack_vectors} & True & True \\
%         \ref*{hyp:sw_multiproc} & \gethyptext{hyp:sw_multiproc} & True & True \\
%         \ref*{hyp:cap_in_vec_storage} & \gethyptext{hyp:cap_in_vec_storage} & True & True \\
%         \ref*{hyp:cap_in_vec_load_store} & \gethyptext{hyp:cap_in_vec_load_store} & True & True \\
%         \ref*{hyp:cap_in_vec_manip} & \gethyptext{hyp:cap_in_vec_manip} & True & True \\
%         \bottomrule
%     \end{tabular}
%     \caption{Hypothesis summary table}
%     \label{tab:hypothesis_outcome}
% \end{table}

% \section{Conclusion}
% \todomark{a conclusion}
% It is clear that scalable vector models should not be a barrier for CHERI.
% \todomark{The artifacts for this project are publicly available, see appendix blah}

\end{document}