\section{Developing the emulator}\label{chap:software:sec:emu}
Rust was selected due to its memory safety and runtime speed, and provides language constructs that suit themselves well to emulation.
Rust Enums are equivalent to \enquote{variant} types in other languages like C++, which \todomark{}.
\todomark{something something match statements}.

\subsection{Basic emulation}
The emulator for each architecture follows a similar pattern.
A \code{Processor} struct stores the register file and the available RAM.
A separate \code{ProcessorModules} struct holds all ISA modules the processor can execute (e.g. the base RV64 Integer ISA, the Multiply extension, and the Vector extension).

The gap between the \code{Processor} and the ISA modules is bridged by a module-specific ``connector'' struct, which holds references to data in the \code{Processor} that is required by the ISA module.
For example, the RV64 Integer ISA's connector contains the current PC, a virtual reference to a register file, and a virtual reference to memory.
This allows different \code{Processor} structs (e.g. a normal RV64 and a CHERI-enabled RV64) to reuse the same ISA modules despite using different register file implementations.

Each \code{Processor} implements a single stage pipeline.
Instructions are fetched, decoded with a common decoder function\footnote{The decoder, and therefore all emulated processors, doesn't support RISC-V Compressed instructions.}, and executed.
The processor asks each ISA module in turn if it wants to handle the instruction, and uses the first module to say yes.
If the ISA module returns a new PC value it is immediately applied, otherwise it is automatically incremented.
This structure easily represents basic RISC-V architectures, and can scale up to support many different new modules.

\todomark{What did the emulator set out to emulate? i.e. no supervisor, pure-capability code only}

\subsection{Emulating CHERI}

Manipulating CHERI capabilities securely and correctly is a must for any CHERI-enabled emulator.
Capability encoding logic is not trivial by any means, so the \code{cheri-compressed-cap} C library was re-used rather than implementing it from scratch.
Rust has generally decent interoperability with C, but some of the particulars of this library caused issues.

\subsubsection{\code{rust-cheri-compressed-cap}}
\code{cheri-compressed-cap} provides two versions of the library by default, for 64-bit and 128-bit capabilities, which are generated from a common source through extensive use of the preprocessor.
Each variant defines a set of preprocessor macros (e.g. the widths of various fields) before including two common header files \code{cheri\_compressed\_cap\_macros.h} and \code{cheri\_compressed\_cap\_common.h}.
The latter then defines every relevant structure or function based on those preprocessor macros.
For example, a function \code{compute_base_top} is generated twice, once as  \code{cc64\_decompress\_mem} returning \code{cc64\_cap\_t} and another time as \code{cc128\_decompress\_mem} returning \code{cc128\_cap\_t}.
Elegantly capturing both sets was the main challenge for the Rust wrapper.

\todomark{table of relevant structures/functions?}

One of Rust's core language elements is the Trait - a set of functions and \enquote{associated types} that can be \emph{implemented} for any type.
This gives a simple way to define a consistent interface for two different data types: define a trait \code{CompressedCapability} with all of the functions from \code{cheri\_compressed\_cap\_common.h}, and implement it for both.
In the future, this would allow the Morello versions of capabilities to be added easily.
A struct \code{CcxCap<T>} is also defined which uses specific types for addresses and lengths pulled from a \code{CompressedCapability}.
For example, the 64-bit capability structure holds a 32-bit address value, and the 128-bit capability a 64-bit address.

128-bit capabilities can cover a 64-bit address range, and thus can have a length of $2^{64}$.
Storing this length requires 65-bits, so all math in \code{cheri\_compressed\_cap\_common.h} uses 128-bit length values.
C doesn't have any standardized 128-bit types, but GCC and LLVM provide so-called ``extension types'' which are used instead.
However, the x86-64 ABI doesn't define any rules for how 128-bit values must be stored or passed as arguments\todocite{x86-64 ABI rules}, which causes great pain to anyone who needs to pass them across a language boundary i.e. us\footnote{Rust explicitly warns against passing 128-bit values across FFI, and the Clang users manual even states that passing \code{i128} by value is incompatible with the Microsoft x64 calling convention\todocite{clang/docs/UsersManual.rst:3384}.}.
While this can be resolved through close examination\footnote{For example, on LLVM 128-bit values are passed to functions in two 64-bit registers\todocite{LLVM 13 clang/lib/CodeGen/TargetInfo.cpp:2941}. This could be replicated in Rust by passing two 64-bit arguments rather than one 128-bit one.}, instead we take advantage of Rust compiling with LLVM under the hood to assume the 128-values on both sides have equal semantics.

\todomark{C code wasn't documented, Rust is}
\todomark{document the rust code :)}

The CHERI-RISC-V documentation contains formal specifications of all the new CHERI instructions, expressed in the Sail architecture definition  language\todocite{https://github.com/rems-project/sail}.
These definitions are used in the CHERI-RISC-V formal model (\todocite{https://github.com/CTSRD-CHERI/sail-cheri-riscv}), and require a few helper functions (see \todocite{TR-951 Ch8.2}).
To make it easier to port the formal definitions directly into the emulator the \code{rust-cheri-compressed-cap} library also provides those helper functions through a wrapper trait.

\todomark{documentation is available on a github.io, not crates.io yet because I don't have access to CSTRD-CHERI and they'd likely want to host it}

\subsubsection{Integrating into the emulator}
% i.e. using MemoryOf trait to make all memory addressable only by capabilities
Integrating capabilities into the emulator was relatively simple thanks to the modular emulator structure.
A capability-addressed memory type was created, which wraps a simple integer-addressed memory in logic which performs the relevant capability checks.
For integer encoding mode, a further integer-addressed memory type was created which wraps the capability addressed mode, where all integer addresses are bundled with the DDC before passing through to the capability-addressed memory.
Similarly, a merged capability register file type was created that exposed integer-mode and capability-mode accesses.
This layered approach meant code for basic RV64I operations did not need to be modified to handle CHERI at all - simply passing the integer-mode memory and register file would perform all relevant checks.

\todomark{diagram}

% i.e. isn't the module system nice for overriding specific behaviour like Capability-mode RV64I :)
Integrating capability instructions was also simple.
Two new ISA modules were created: \code{XCheri64} for the new CHERI instructions, and \code{Rv64imCapabilityMode} to override the behaviour of legacy instructions in capability-encoding-mode.
\todomark{show the program flow for using modules}
The actual Processor structure was left mostly unchanged - integer addresses were changed to capabilities throughout, and the DDC was added (although with no ability 
Memory and register file types were changed as described above and the PCC/DDC were added.

% i.e. doing capability relocation
The final hurdle was the capability relocations outlined in \todoref{capability relocations}.
Because we're emulating a bare-metal platform, there is no operating system to do this step for us.
A bare-metal C function has been written to perform the relocations\todocite{https://github.com/CTSRD-CHERI/device-model/blob/master/src/crt_init_globals.c}, which could be compiled into the emulated program.
However, I was skeptical of how to find the addresses of the generated relocations in C, so I performed the relocations in Rust by examining the compiled ELF file before starting emulation.
In future research it should be doable to perform the relocations entirely in bare-metal C.

\subsection{Emulating vectors}
% i.e. using addr, provenance split to write agnostic code?

Vector instructions are executed by a Vector ISA module, which stores all registers and other state.
\code{VLEN} is hardcoded as 128-bits, and the maximum \code{ELEN} is \todomark{64} 32-bits.
To support both CHERI and non-CHERI execution pointers are separated into an address and a \emph{provenance} - \todomark{short definition of provenance}.
The vector unit retreives an address + provenance pair from the base register, generates a stream of addresses to access, then rejoins each address with the provenance to access memory.
On CHERI, provenance is defined in terms of the base register e.g. \enquote{the provenance is provided by capability register X}.
On non-CHERI platforms, provenance has no meaning and is not checked.

Arithmetic and configuration instructions are generally simple to implement, so aren't covered here.
The emulator splits memory access instructions into three phases: decoding (\todoref{}), fast-path (\todoref{}), and execution (\todoref{}).
A separate decoding stage may technically not be necessary in hardware (especially the parts checking for errors and reserved instruction encodings, which a hardware platform could simply assume won't happen), but it allows each memory access instruction to be classified into one of the five archetypes outlined in \todoref{chap:bg:sec:rvv:memoryaccessinstrs}.
It is then easy to define the fast-path and execution phases separately for each archetype, as the hardware would need to do.

\subsubsection{Decoding phase}
Decoding is split into two steps: finding the encoded \paramt{nf} and \paramt{eew} values, then interpreting them based on the encoded archetype.
% Vector memory accesses are encoded under the F extension's Load and Store major opcodes, which already encodes an element width.
Vector memory access instructions are encoded similarly to the F extension's floating-point load/store instructions, which include an ``element width''.
The vector extension adds four extra ``element width'' values which imply the access is vectorized.
% This element width is used to differentiate between vector accesses and scalar floating-point accesses, where a vector access can have one of four widths (8, 16, 32, 64).
If any of these values are found, the instruction is interpreted as a vector access and \paramt{nf} is extracted.
% \paramt{nf} is encoded consistently in all vector memory access instructions

Once the generic parameters are extracted, the \paramt{mop} is checked to determine the indexing method (Unit, Strided, Indexed-Ordered, or Indexed-Unordered).
If a unit access is selected, the second argument field encodes an extra value to choose between different unit-stride archetypes (normal unit access, fault-only-first, whole register, or bytemask).
Strided and indexed accesses just use their dedicated archetypes.
Once the archetype is found supplemental calculations can be performed (e.g. computing \code{EVL = ceil(vl/8)} for bytemask accesses) and the relevant information is returned as a \code{DecodedMemOp} enumeration.

\todomark{diagram of floating point ld/st vs. vector ld/st}
\todomark{Decision tree for operation decoding}

\subsubsection{Fast-path check phase}
The initial motivation for this project was investigating the impact of capability checks on performance.
One approach that we immediately hit upon was the concept of a \enquote{fast path}, where certain instructions could check their whole access range against a capability immediately rather than check each individual element.
Because CHERI, and indeed the vector extension, target all levels of computer architecture from embedded systems to cloud servers, it's important for these fast-paths to be scalable and adjust to the implementation complexity.
To that end, we propose a method of generating the address range for accesses of each archetype, noting where architectural complexity can be traded off for tighter coverage.

In some cases, a failed address range check may not mean the access fails.
The obvious case is fault-only-first loads, where synchronous exceptions (such as capability checks) are explicitly handled.
The address range calculations ignore masking in all cases\footnote{Shrinking the address range to remove masked-out elements would likely require a linear search through all elements, which makes the fast-path redundant.} so even if the address range falls outside the capability bounds, the individual accesses outside those bounds could all be masked out.
Therefore a fast-path check can have three outcomes:
\begin{itemize}
    \item Success - All accesses will succeed
    \begin{itemize}
        \item The fast-path address range is entirely contained by the capability
    \end{itemize}
    \item Failure - At least one access \emph{must} fail, triggering a synchronous exception.
    \begin{itemize}
        \item The fast-path address range is not entirely contained by the capability
        \item Not a fault-only-first access
        \item Not a masked access
    \end{itemize}
    \item Indeterminate - At least one access \emph{may} fail
    \begin{itemize}
        \item The fast-path address range could not be calculated, or is not entirely contained by the capability for fault-only-first and masked accesses.
    \end{itemize}
\end{itemize}

\todomark{tight vs superset range?}

In the case of indeterminate failure, accesses need to be individually checked to see if failure actually occurs.
If precise exceptions are used, even the failure case needs to perform each individual access to ensure accesses before the offending element are completed.
Because all access archetypes may be masked, therefore the fast-path check may always be indeterminate, implementations must always contain a slow-path fallback option which does each access in turn for every archetype.
% This slow-path 
% In cases where precise exceptions are used, this slow-path must also respect the necessary ordering guarantees.
% \todomark{this isn't a good place to talk about precise exceptions/ordering}

% If masking is enabled, any elements that cause the address range check to fail could be masked out.
% In all cases masking is ignored - masked-out elements should not trigger capability checks or capability failure \todomark{why?} but checking 

\noindent\emph{Unit accesses}\\
\noindent For unit segmented accesses, which includes fault-only first, the tight address range for an access is
$base + [vstart * nf * eew, evl * nf * eew)$.
Unit unsegmented accesses where $nf = 1$, which includes whole register and bytemask accesses, can simplify this by fixing \code{nf} and \code{eew}.

\code{nf} is not guaranteed to be a power of two (except for the whole-register case), so calculating the `tight' address range would require a multiplication by an arbitrary four-bit value between 1 and 8.
If this multiplication is too expensive, implementations could choose to classify all $nf > 1$ cases as indeterminate.
\todomark{if nf == 1; as normal; if nf != 1 indeterminate}

Unless extra restrictions are placed on \code{vstart} calculating the start of this range requires another arbitrary multiplication.
To avoid this, one could assume \code{vstart} is zero for the calculation, perform the capability check and treat failures as indeterminate (because the failure could be due to an element before \code{vstart}).
\todomark{make it clear that in this case vstart = 0 would still be a complete failure}
Once could also classify all nonzero \code{vstart} accesses as indeterminate immediately, without performing any calculations.
\todomark{if vstart == 0 failure = failure; if vstart != 0 all = indeterminate}

Even if the previous two optimizations are applied, the final range still requires a multiplication $evl * eew$.
Thankfully, because \paramt{eew} may only be one of four powers-of-two, this can be encoded as a simple shift.


\noindent\emph{Strided accesses}\\
\noindent Strided accesses bring further complication, especially as the stride may be negative.
For a $stride >= 0$ : $base + [vstart * stride, (evl - 1) * stride + nf * eew)$
For $stride < 0$: $base + [(evl - 1) * stride, vstart * stride + nf * eew)$

This is formed of three components:
\begin{itemize}
    \item $vstart * stride$, the start of the first segment. This can be simplified as 0, just like for unit accesses, to avoid an arbitrary multiplication.
    \item $(evl - 1) * stride$, the start of the final segment. This requires an arbitrary multiplication, unless strided accesses are not fast-pathed at all.
    \item $nf * eew$, the length of a segment, which can be implemented with a shift.
\end{itemize}
% Because the stride is not guaranteed to be larger than a segment (or even larger than a single element)

% \todomark{stride may be negative}

\noindent\emph{Indexed accesses}\\
\noindent This is the most complicated access of the bunch, because the addresses cannot be computed without reading the index register.

$base + [min(offsets[vstart..evl]), max(offsets[vstart..evl]) + nf * eew)$

The most expensive components here are of course $min,max$ of the offsets.
These could be calculated in hardware through parallel reductions, making it slightly more efficient than looping over each element.
A low-hanging optimization could be to remove the $vstart..evl$ range condition, performing the reduction over the whole register group, which would make failures indeterminate where $vstart != 0 || evl != VLMAX$.
This calculation could also be restricted to certain register configurations to reduce the amount of required hardware.
Indeed, the amount of hardware could be reduced to zero by simply classifying all indexed accesses as indeterminate.

\subsubsection{Execution phase}
If the fast-path check is successful or indeterminate, the emulator performs all accesses in order, checking each address against the capability.
Any capability failure triggers an immediate synchronous exception, performing a precise trap \todomark{altho vstart isn't set?}
If the fast-path check is unsuccessful, the emulator immediately returns (thus performing an imprecise trap) \todomark{although it doesn't yet correctly set vstart}.
For readability, the emulator separates this into two phases: determining the mapping of vector elements to accessed memory addresses, then performing those accesses.
The pseudocode for each access can be found in \todoref{appendix}, and this step is otherwise not noteworthy.