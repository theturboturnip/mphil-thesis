\subsection{Emulating vectors}
% i.e. using addr, provenance split to write agnostic code?

Vector instructions are executed by a Vector ISA module, which stores all registers and other state.
\code{VLEN} is hardcoded as 128-bits, chosen because it's the largest integer primitive provided by Rust that's large enough to hold a capability.
\code{ELEN} is also 128-bits, which isn't supported by the specification, but is required for capabilities-in-vectors (\cref{chap:capinvec}).
Scaling \code{VLEN} and \code{ELEN} any higher would require the creation and integration of new types that were more than 128-bits long.

To support both CHERI and non-CHERI execution pointers are separated into an address and a \emph{provenance}\footnote{The ``original allocation the pointer is derived from''\cite{memarianExploringSemanticsPointer2019}, or in CHERI terms the bounds within which the pointer is valid.}.
The vector unit retrieves an address + provenance pair from the base register, generates a stream of addresses to access, then rejoins each address with the provenance to access memory.
When using capabilities, provenance is defined in terms of the base register e.g. \enquote{the provenance is provided by capability register X}, or defined by the DDC in integer mode\footnote{See \cref{chap:emu:rvv_int_mode} for the reasoning behind this decision.}.
On non-CHERI platforms the vector unit doesn't check provenance.

Arithmetic and configuration instructions are generally simple to implement, so aren't covered here.
The emulator splits vector memory accesses into three phases: decoding, checking, and execution.
A separate decoding stage may technically not be necessary in hardware (especially the parts checking for errors and reserved instruction encodings, which a hardware platform could simply assume won't happen), but it allows each memory access instruction to be classified into one of the five archetypes outlined in \cref{chap:bg:sec:rvvmemory}.
It is then easy to define the checking and execution phases separately for each archetype, as the hardware would need to do.

\subsubsection{Decoding phase}\label{chap:hardware:subsec:decoding}
Decoding is split into two steps: finding the encoded \paramt{nf} and \paramt{eew} values, then interpreting them based on the encoded archetype.
% Vector memory accesses are encoded under the F extension's Load and Store major opcodes, which already encodes an element width.
% Vector memory access instructions are encoded similarly to the F extension's floating-point load/store instructions, which include an ``element width''.
Vector memory accesses reuse instruction encodings from the F extension's floating-point load/store instructions, which include an ``element width''.
The vector extension adds four extra ``element width'' values which imply the access is vectorized.
% This element width is used to differentiate between vector accesses and scalar floating-point accesses, where a vector access can have one of four widths (8, 16, 32, 64).
If any of these values are found, the instruction is interpreted as a vector access and \paramt{nf} is extracted.
% \paramt{nf} is encoded consistently in all vector memory access instructions

Once the generic parameters are extracted, the addressing method is determined from \paramt{mop} (Unit, Strided, Indexed-Ordered, or Indexed-Unordered).
If a unit access is selected, the second argument field \paramt{umop} selects a unit-stride archetype (normal access, fault-only-first, whole register, or bytemask).
% Strided and indexed accesses just use their dedicated archetypes.
Extra archetype-specific calculations are performed (e.g. computing \code{EVL = ceil(vl/8)} for bytemask accesses), and the relevant information is returned as a \code{DecodedMemOp} enum.

% \todomark{diagram of floating point ld/st vs. vector ld/st}
% \todomark{table of floating point ld/st, vector ld/st instructions}
\todomark{appx - Decision tree for operation decoding?}

\newcommand{\mcb}[2]{\multicolumn{#1}{|c|}{#2}}
\begin{table}
    % \begin{tabularx}{\textwidth}{@{}*{32}{p{\dimexpr(\textwidth-64\tabcolsep)/32\relax}}@{}}
    \small\begin{tabularx}{\textwidth}{XXXX XXXX XXXX XXXX XXXX XXXX XXXX XXXX}
    % \small\begin{tabularx}{\textwidth}{p{}}
                % \begin{tabular}{*{32}{p{3cm}}}
            % 31&&29&28&27&26&25&24&&&&20&19&&&&15&14&&12&11&&&&7&6&&&&&&0 \\
        \hline
        \mcb{3}{nf} & mew & \mcb{2}{\paramt{mop}} & vm & \mcb{5}{\paramt{umop}/rs2/vs2} & \mcb{5}{rs1} & \mcb{3}{width} & \mcb{5}{vd} & \mcb{7}{Opcode} \\
        \hline
    \end{tabularx}
    \caption{Floating-point and Vector load/store encoding}
    \todomark{fix}
\end{table}

\subsubsection{Fast-path checking phase}\label{chap:hardware:subsec:checking}
The initial motivation for this project was investigating the impact of capability checks on performance.
Rather than check each element's access invidually, we determine a set of \enquote{fast-path} checks which count as checks for multiple elements at once.
In the emulator, this is done by computing the \enquote{tight bounds} for each access, i.e. the exact range of bytes that will be accessed, and doing a single capability check with that bounds.
\cref{chap:hardware:sec:fastpath} describes methods for calculating the \enquote{tight bounds} for each access type, and ways that architectural complexity can be traded off to calculate \emph{wider} bounds.

% We investigate an approach using a \enquote{fast-path}, where certain instructions could check their whole access range against a capability immediately rather than check each individual element.
% Other approaches, such as optimizing a parallel checker for $n$ elements, were too hardware-specific and couldn't be modelled in software as well.
% \cref{chap:hardware:sec:fastpath} describes methods for calculating the \enquote{tight bounds} for each access type, i.e. the minimum range of bytes that must be accessible, and ways that architectural complexity can be traded off to calculate \emph{wider} bounds.

If the tight bounds don't pass the capability check, the emulator raises an imprecise trap and stops immediately.
In the case of fault-only-first loads, where synchronous exceptions (e.g. capability checks) are explicitly handled, the access continues regardless and elements are checked individually.
This is also the expected behaviour if a capability check for \emph{wider} bounds fails.
The emulator deviates from the spec in that \code{vstart} is \emph{not} set when the tight bounds check fails, as it does not know exactly which element would have triggered the exception.
As noted in \cref{chap:hardware:sec:fastpath}, a fully compliant machine must check each access to find \code{vstart} in these cases.

\subsubsection{Execution phase}\label{chap:hardware:subsec:execution}
If the fast-path check deems it appropriate, the emulator continues execution of the instruction in two phases.
First, the mapping of vector elements to accessed memory addresses is found.
The code for this step is independent of the access direction, and an effective description of how each type of access works.
It can be found in \cref{appx:code:vector_mem_access}.
The previously computed tight bounds are sanity-checked against these accesses, and the accesses are actually performed.

\subsubsection{Integer vs. Capability encoding mode\label{chap:emu:rvv_int_mode}}
As noted in \cref{chap:bg:subsec:cheriencodingmode} CHERI-RISC-V defines two execution modes that the program can switch between.
In Integer mode \enquote{address operands to existing RISC-V load and store opcodes contain integer addresses} which are implicitly dereferenced relative to the default data capability, and in Capability mode those opcodes are modified to use capability operands.
Integer mode was included in the interests of maintaining compatibility with legacy code that hasn't been adapted to capabilities.
As similar vector code may also exist, CHERI-RVV treats vector memory access instructions as \enquote{existing RISC-V load and store opcodes} and requires that they respect integer/capability mode.