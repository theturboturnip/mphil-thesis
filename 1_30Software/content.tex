\documentclass[../thesis]{subfiles}
\begin{document}

\chapter{The CHERI-RVV software stack\label{chap:software}}
This chapter explores the current state of the CHERI-RVV software stack: mainstream compiler support for vanilla RVV (\cref{chap:software:sec:compilersupport}) and the modifications required to bring support to CHERI-Clang (\cref{chap:software:sec:chericlang}).
The software hypotheses are tested with this knowledge (\cref{chap:software:sec:hypotheses}), and we recommend a set of changes to bring CHERI-Clang support to par with other compilers (\cref{chap:software:sec:chericlangchanges}).
% First, the available compiler support for vanilla RVV is explored and briefly compared to Arm SVE .
% that translates to CHERI-Clang and what changes were necessary to implement capabilities, and 

\section{Compiling vector code}\label{chap:software:sec:compilersupport}
Modern compilers provide many ways to generate vectorized code.
While this support is very advanced for well established vector models, like x86-64 AVX, newer vector models like RVV don't have as many options.
It can even be difficult to get the compiler to generate any vector instructions at all.
This section examines support across the Clang and GCC compilers for various vectorization methods on RVV.

\subsection{Available compilers}
% Before you can compile vector code, the compiler must be told to use a vector ISA.
Compiler support for RVV varies.
On Clang 13 and other LLVM-13-based compilers, version 0.1(?\footnote{It is difficult to verify the actual corresponding version, because there is no readily available specification for v0.1, and the extension supports instructions only present from v0.8 such as whole register accesses.}) of the vector specification is supported as an experimental extension.
Clang/LLVM~14 and up support RVV v1.0.

GCC is an interesting case --- there is a version based on RISC-V GCC 10.1 that partially supports RVV (see \cref{compilerdifferences}), but it was left untouched for a year and deleted as of 17th May 2022.
GCC RVV support has also been deprioritized in favour of LLVM\footnote{\url{https://github.com/riscv-collab/riscv-gcc/issues/320}}.
See \cref{appx:building_rvv_gcc_toolchain} for more information on finding and building this version, and \cref{tab:rvv_cmdline_nocheri} for the required command-line arguments to enable RVV.

\subsection{Automatic vectorization}
\todomark{Figure page showing generated ASM for increment loop - see godbolt links MD}
Compilers with auto-vectorization can automatically create vectorized code from a scalar program.
For example, a scalar loop over an array that increments each element could be converted to a vectorized loop that increments multiple elements at once.
% Although this is simple in some cases, auto-vectorization can take significant effort and time to implement (for example, GCC started implementing it for x86 in 2003 and only turned on basic support in 2007\footnote{\url{https://gcc.gnu.org/projects/tree-ssa/vectorization.html}}).
Clang and GCC support auto-vectorization in Arm SVE, explored further in \cref{chap:soft:compiling:armsve}, but don't yet support it for RVV.
Arm SVE and RVV are quite similar, so there shouldn't be anything blocking auto-vectorization for RVV, it just requires engineering effort.
% There's nothing preventing RVV auto-vectorization, especially as the similar Arm SVE model has auto-vectorization (see \cref{chap:soft:compiling:armsve}), but currently Clang and GCC do not support it.
% Currently there is no support for RVV auto-vectorization in Clang or GCC.
% Both compilers have support for Arm SVE auto-vectorization, explored further in \cref{chap:soft:compiling:armsve}.

\subsection{Vector intrinsics}
\enquote{Intrinsics} are functions defined by the compiler that can invoke low-level functionality and instructions directly for a specific architecture.
When automatic vectorization is not available, intrinsics are the next best thing --- they aren't portable across different ISAs, but present a familiar high-level interface (function calls) that gives fine-grained control over instructions.
% RVV provides an intrinsic for each vector instruction.
The compiler then handles low-level decisions like register allocation under the hood, and sometimes may provide extra functionality for ease of use.

RVV has a comprehensive set of vector intrinsics\cite{specification-RVV-intrinsics}.
%, implemented in the aforementioned special version of GCC and Clang~13+.
With these, the general strip-mining loop is easy to construct:
\todomark{example based on \url{https://github.com/riscv-non-isa/rvv-intrinsic-doc/blob/master/examples/rvv_memcpy.c}}
\begin{enumerate}
    \item Use a \code{vsetvl} intrinsic to get the vector length for this iteration.
    \item Allocate vector registers by declaring variables with vector types (e.g. \code{vuint32m8_t} represents 8 registers worth of 32-bit unsigned integers).
    \item Pass the vector length to the computation/memory intrinsics, which operate on the vector variables.
\end{enumerate}

\subsection{Inline assembly}
If a compiler doesn't supply complete intrinsics, or if the programmer desires even more control, inline assembly may be used.
The programmer gives a string of handwritten assembly code to the compiler, which is parsed and directly inserted into the output code.
The compiler still has to understand the instruction, but it doesn't need intrinsics to be present (or functional\footnote{As described later, CHERI-Clang crashes when intrinsics are used, so we use inline assembly instead.}).
% We used this for CHERI-Clang programs, as it could not use intrinsics without crashing.

Inline assembly can interact with C code and variables through a template syntax.
The programmer inserts a placeholder in the assembly code with a corresponding expression, noting how the expression is stored using a \enquote{constraint}.
For our purposes, constraints enforce that a value is either in a register or in memory.

Using the constraint, the compiler determines how the expression's value is stored, and inserts a reference to it in the assembly string.
Because this is done before the assembly string is parsed, and isn't immediately type-checked against the assembly instruction, it can lead to some difficult errors.

Clang and GCC support inline assembly for RVV quite well, and even allows the intrinsic vector types to be referenced by assembly templates (thus making the compiler do register allocation instead of the programmer).
The only caveat is that \emph{memory} constraints are not supported by RVV memory accesses.
None of the vector memory access instructions support address offsets, unlike their scalar counterparts.
Clang always treats the memory constraint as an offset access, even when that offset is zero, so it adds an offset to the assembly string (\cref{subfig:inline_asm_vector_memory}) making it invalid.
To get around this, one must use the pointer itself with a \emph{register} constraint (\cref{subfig:inline_asm_vector_ptr_reg}).
% On CHERI platforms, because pointers must be stored in capability registers, the \emph{capability register} constraint must be used instead (\cref{subfig:inline_asm_vector_cap_reg}).

\begin{figure}[hb]
    \centering
    \begin{subfigure}{0.6\textwidth}
        \inputframedminted[gobble=4,firstline=6,lastline=6]{c}{./code/inline_asm.c}
        \caption{Preamble}
    \end{subfigure}

    \vspace{1em}
    \begin{subfigure}{0.49\textwidth}
        \inputframedminted[gobble=4,firstline=7,lastline=10]{c}{./code/inline_asm.c}
        \caption{Load scalar from memory}\label{subfig:inline_asm_memory}
    \end{subfigure}\hfill%
    \begin{subfigure}{0.49\textwidth}
        \inputframedminted[gobble=4,firstline=20,lastline=23]{c}{./code/inline_asm.c}
        \caption{Failed attempt to load vector from memory}\label{subfig:inline_asm_vector_memory}
    \end{subfigure}

    \vspace{1em}
    \begin{subfigure}{0.49\textwidth}
        \inputframedminted[gobble=4,firstline=32,lastline=35]{c}{./code/inline_asm.c}
        \caption{Load vector from pointer in register}\label{subfig:inline_asm_vector_ptr_reg}
    \end{subfigure}    

    \caption{Inline assembly examples\\\url{https://godbolt.org/z/rW9orr66a}}\label{fig:inlineasm}
\end{figure}

Broadly speaking, inline assembly supports more RVV instructions than intrinsics do.
It is used extensively in the testbench code for the evaluation (\cref{chap:software:eval}) alongside intrinsics where possible.

\pagebreak
\subsection{RVV vs. Arm SVE}\label{chap:soft:compiling:armsve}
Arm SVE uses a similar model to RVV, where the vector length may scale between 128 and 2048\footnote{RVV slightly differs here, as it allows VLEN smaller than 128.} and the instructions are designed to be totally agnostic across different platforms\cite{stephensARMScalableVector2017}.
Arm have released a C language extension to support SVE development (\cite{armltdARMLanguageExtensions2020}), supported by the Arm Compiler for Embedded\footnote{\url{https://developer.arm.com/Tools\%20and\%20Software/Arm\%20Compiler\%20for\%20Embedded}}, Clang, and GCC.
They support all of the previously examined vectorization types.

Auto-vectorization is supported, and the main focus of the user guide (\cite{armltdArmCompilerScalable2019}) is helping the compiler decide whether to auto-vectorize.
Intrinsics are also supported, and seem to cover all of the SVE instructions, but take a slightly different approach to RVV.
Arm SVE intrinsics do not directly map to available instructions, but aim to \enquote{provide a regular interface and leave the compiler to pick the best mapping to SVE instructions}, while RVV intrinsics (at least for memory) tend to map 1:1 to existing instructions.
Arm's approach gives more flexibility for future extensions, as the same intrinsics could be compiled to new instructions with newer compilers.

Arm SVE also supports inline assembly, but the experience is notably worse than for RVV.
The two standout issues are a lack of register allocation and the use of condition code flags for branching.
Unlike RVV, the intrinsic types for vector values cannot be referenced in inline assembly\cite{stephensARMScalableVector2017}, so all vector registers must be allocated and tracked by the programmer.
Arm SVE's equivalent of \code{vsetvl}, the \code{while} family\cite{armltdARMLanguageExtensions2020}, do not return the number of updated elements, and instead set the condition flags based on how many elements are updated.
Because there is no way to branch based on the condition flags in C, the programmer must manually insert a label for the top of the loop, and a branch to that label (see \url{https://godbolt.org/z/zoWh9jq3o}), which is more error prone than the RVV method.
Examples of Arm SVE code with auto-vectorization, intrinsics, and inline ASM can be found in \todomark{appendix based on \url{https://godbolt.org/z/zoWh9jq3o}}.

\begin{figure}
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \inputframedminted[gobble=4,firstline=43,lastline=46]{c}{./code/inline_asm.c}
        \caption{Load vector from capability in register}\label{subfig:inline_asm_vector_cap_reg}
    \end{subfigure}\hfill{}
    \begin{subfigure}[t]{0.54\textwidth}
        \centering
        \inputframedminted[gobble=4,firstline=57,lastline=67]{c}{./code/inline_asm.c}
        \caption{Portable code for CHERI and non-CHERI\parnote{This relies on the \code{pure\_capabilities} feature flag, which was added to CHERI-Clang for this project.}.}\label{subfig:inline_asm_vector_portable}
    \end{subfigure}
    \parnotes{}
    \caption{Inline assembly examples (CHERI)}\label{fig:inlineasmcheri}
\end{figure}

\pagebreak
\section{Compiling vector code with CHERI-Clang}\label{chap:software:sec:chericlang}
Current CHERI compiler work is done on CHERI-Clang, a fork of Clang and other LLVM tools that supports capabilities.
It's based on LLVM~13, and supports vanilla RVV v0.1, but the vector-related code had not been updated to handle capabilities.
% This section outlines the changes made to CHERI-Clang, and the changes required for vector code, to compile programs for CHERI-RVV.
This section outlines the changes required to compile vector programs for CHERI-RVV using CHERI-Clang.
The required command-line options for CHERI-Clang are noted in \cref{chericlang_cmdline}.

\subsection{Adapting vector assembly instructions to CHERI}\label{addingtochericlang}
LLVM uses a domain-specific language to describe the instructions it can emit for a given target.
The RISC-V target describes multiple register sets that RISC-V instructions can use.
Vanilla RVV vector memory accesses use the General Purpose Registers (GPR) to store the base address of each access.
CHERI-Clang added a GPCR set, i.e. the General Purpose Capability Registers, which use a different register constraint.
We created two mutually exclusive versions of each vector access instruction: one for integer mode using a GPR base address; and one for capability mode using GPCR.
% As noted in \cref{chap:emu:rvv_int_mode}, CHERI-RVV requires the vector memory accesses to support integer \emph{and} capability mode, so each vector
% two versions of the vector accesses are created:
% versions which take a capability base address, only available in CHERI/Capability mode, and versions which take integer base addresses for Integer mode.

With the above changes, inline assembly could be used to insert capability-enabled vector instructions (\cref{subfig:inline_asm_vector_cap_reg}).
However, as this requires using a capability register constraint for the base address, inline assembly code written for CHERI-RVV is not inherently compatible with vanilla RVV.
For un-annotated pointers (e.g. \code{int*}), which are always capabilities in pure-capability code and integers in legacy or hybrid code, a conditional macro can be used to insert the correct constraint (\cref{subfig:inline_asm_vector_portable}).
However, this falls apart in hybrid code for manually annotated pointers (e.g. \code{int* \_\_capability}) because the macro cannot detect the annotation.

\subsection{Adapting vector intrinsics to CHERI}
Vector intrinsics are another story entirely.
When compiling for pure-capability libraries, all attempts to use vector intrinsics crash CHERI-Clang.
This is due to a similar issue to inline assembly: the intrinsics (both the Clang intrinsic functions and the underlying LLVM IR intrinsics) were designed to take regular pointers and cannot handle it when capabilities are used instead.
% \todomark{Appendix which covers what I know so far about this problem?}
Unfortunately the code for generating the intrinsics is spread across many files, and there's no simple way to change the pointers to capabilities (much less changing it on-the-fly for capability vs. integer mode).

It seems that significant engineering work is required to bring vector intrinsics up to scratch on CHERI-Clang.
We did experiment with creating replacement wrapper functions, where each function tried to mimic an intrinsic using inline asssembly.
These were rejected for two reasons: the overhead of a function call for every vector instruction\footnote{We tried using preprocessor macros instead of real functions, but they are difficult to program and do not support returning values like intrinsics do.}, and lack of support for passing vector types as arguments or return values.
The RISC-V ABI treats all vector registers as temporary and explicitly states that \enquote{vector registers are not used for passing arguments or return values}\cite{specification-RISCV-ABI-v1.0rc2}.
CHERI-Clang would try to return them by saving them to the stack, but this had its own issues.
% Even if we wanted to change that, because the registers and CHERI has its own issues with saving vector registers on the stack.

% \todomark{segue into saving registers on stack doesn't make sense - doesn't explain why someone would want to}

\subsection{Storing scalable vectors on the stack}
If a program uses more data than can fit in registers, or calls a function which may overwrite important register values, the compiler will save those register values to memory on the stack.
Because vector registers are temporary, and thus may be overwritten by called functions, they must also be saved/restored from the stack\todomark{Example https://godbolt.org/z/KPTW7rcvY}.
This also applies to multiprocessing systems where a process can be paused, have the state saved, and resume later.
RVV provides the whole-register memory access instructions explicitly to make this process easy\cite[Section 7.9]{specification-RVV-v1.0}.

CHERI-Clang contains an LLVM IR pass\footnote{\gitfile{llvm/lib/CodeGen/CheriBoundAllocas.cpp}{CTSRD-CHERI/llvm-project}{https://github.com/CTSRD-CHERI/llvm-project/blob/master/llvm/lib/CodeGen/CheriBoundAllocas.cpp}} which enforces strict bounds on so-called ``stack capabilities'' (capabilities pointing to stack-allocated data), which by definition requires knowing the size of the data ahead of time.
This pass assumes all stack-allocated data has a static size, and crashes when dynamically-sized types e.g. scalable vectors are allocated.
It is therefore impossible (for now) to save vectors on the stack in CHERI-Clang, although it's clear that it's theoretically possible.
For example, the length of the required vector allocations could be calculated based on \code{VLEN} before each stack allocation is performed, or if performance is a concern stack bounds for those allocations could potentially be ignored altogether.
These possibilities are investigated further in the next section.

\pagebreak
\input{1_30Software/sub50_hyp}
\input{1_30Software/sub60_chericlangchanges}

\end{document}